{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_dataframe.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user.favourites_count</th>\n",
       "      <th>user.id</th>\n",
       "      <th>lang</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.verified</th>\n",
       "      <th>truncated</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indirect eu costing britain ¬£170 year! #bette...</td>\n",
       "      <td>31150.0</td>\n",
       "      <td>107794703</td>\n",
       "      <td>en</td>\n",
       "      <td>804</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video: sturgeon post-election deals</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557422508</td>\n",
       "      <td>en</td>\n",
       "      <td>184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://t.co/BTJwrpbmOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>growing david minister today.. #bbcqt ‚Ä¶</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>3006692193</td>\n",
       "      <td>en</td>\n",
       "      <td>182</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://t.co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ukip lothian 16 msn addy</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>455154030</td>\n",
       "      <td>en</td>\n",
       "      <td>1073</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://t.co/7eIU0c5Fm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ukip's spokesman rakes ¬£800k benefit migrants...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>187547338</td>\n",
       "      <td>en</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://t.co/c1AZxcLh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  user.favourites_count  \\\n",
       "0   indirect eu costing britain ¬£170 year! #bette...                31150.0   \n",
       "1                video: sturgeon post-election deals                    0.0   \n",
       "2            growing david minister today.. #bbcqt ‚Ä¶                 7565.0   \n",
       "3                           ukip lothian 16 msn addy                 2130.0   \n",
       "4   ukip's spokesman rakes ¬£800k benefit migrants...                  131.0   \n",
       "\n",
       "      user.id lang user.followers_count user.verified truncated  \\\n",
       "0   107794703   en                  804         False     False   \n",
       "1   557422508   en                  184         False     False   \n",
       "2  3006692193   en                  182         False     False   \n",
       "3   455154030   en                 1073         False     False   \n",
       "4   187547338   en                   87         False     False   \n",
       "\n",
       "                    links  \n",
       "0                     NaN  \n",
       "1  http://t.co/BTJwrpbmOY  \n",
       "2             http://t.co  \n",
       "3  http://t.co/7eIU0c5Fm1  \n",
       "4    http://t.co/c1AZxcLh  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word in Tweet  || Tweet Nos.\n",
      "suicidal [1530]\n",
      "vermin [1806]\n",
      "desirable [710]\n",
      "skynews [387, 469, 856, 889]\n",
      "yellow [186]\n",
      "knell [403]\n",
      "controversial [951]\n",
      "hanging [11, 260]\n",
      "captain [1506]\n",
      "integrity [855]\n",
      "dunleavy138 [16, 766]\n",
      "votes [1807, 1920]\n",
      "voter [436]\n",
      "fuckwits [728]\n",
      "poorest [957]\n",
      "disability [1157, 1481, 1696]\n",
      "xx [1698, 1770]\n",
      "james [1947]\n",
      "maudling [1068, 1649, 1659]\n",
      "worstgovever [540]\n",
      "whatsoever [331]\n",
      "caused [923, 1053, 1177, 1180, 1218, 1829]\n",
      "lord [343]\n",
      "sorry [297, 903]\n",
      "editorship [468]\n",
      "playground [340]\n",
      "mancman10 [985, 1820]\n",
      "risk [499, 502, 591, 987, 1200, 1239]\n",
      "neud [802, 1542]\n",
      "labourites [1407, 1996]\n",
      "aurora [1637]\n",
      "semi [1680]\n",
      "eugenics [1788]\n",
      "dels [602]\n",
      "holyrood [338, 766]\n",
      "govern [454, 519, 694, 806, 925, 1029, 1658]\n",
      "bringing [32, 139, 1214]\n",
      "trade [1661]\n",
      "prize [1017, 1198, 1378, 1812, 1898]\n",
      "ref [1226, 1442, 1613]\n",
      "vitriolic [850, 1019]\n",
      "unrelated [7, 19, 164, 185, 194, 334, 368, 370, 427, 491, 537, 659, 735, 866, 922, 1028, 1063, 1110, 1147, 1152, 1194, 1238, 1499, 1525, 1611, 1716, 1819, 1919]\n",
      "theysay [1261]\n",
      "bettertogether [474, 1402]\n",
      "heading [329, 557, 840]\n",
      "swoons [1161]\n",
      "leaders [93, 202, 373, 584, 777, 927, 1473, 1787, 1908]\n",
      "nigh [938]\n",
      "punning [350, 986]\n",
      "270 [1557]\n",
      "likely [144, 1401]\n",
      "street [515, 884, 1571, 1635]\n",
      "275 [898]\n",
      "iraq [1409]\n",
      "7th [364, 464, 693, 889, 1169, 1582, 1726]\n",
      "y0deex [795]\n",
      "even [463, 1639]\n",
      "neo [559]\n",
      "alun_pugh [802, 1542]\n",
      "presentational [901, 1098, 1434, 1458, 1785]\n",
      "fingers [586, 1727]\n",
      "poison [1948]\n",
      "spokesman [4, 66, 570, 676, 1311, 1565]\n",
      "hull [1795]\n",
      "scottishlabour [152, 181, 318, 448, 1045, 1712, 1736, 1974]\n",
      "new [385, 1046, 1283, 1644]\n",
      "fall [720, 1355, 1747, 1970]\n",
      "ever [273, 296, 626]\n",
      "xa1mbst8nx [687]\n",
      "told [590]\n",
      "pkukpoll [469, 856]\n",
      "kennypieper [1988, 1992]\n",
      "misjudged [1134]\n",
      "chrissalmon [1837]\n",
      "davidpattie [1187]\n",
      "never [804, 1334]\n",
      "ed_milliband [870, 1029, 1658]\n",
      "richest [748]\n",
      "here [7, 19, 71, 72, 74, 164, 185, 189, 194, 201, 334, 368, 370, 391, 427, 491, 500, 537, 659, 668, 735, 866, 922, 1028, 1063, 1110, 1147, 1152, 1194, 1238, 1499, 1525, 1611, 1636, 1716, 1819, 1840, 1919, 1933]\n",
      "lurves [1913]\n",
      "jubbly [563, 953]\n",
      "becm [97]\n",
      "dorm [180]\n",
      "100 [82, 115, 258, 348, 1217, 1278, 1578, 1614]\n",
      "celebration [31, 1547]\n",
      "dry [1126]\n",
      "culling [649]\n",
      "rests [423, 423, 1391, 1391, 1995, 1995]\n",
      "muddying [95]\n",
      "k [400]\n",
      "johngemmell40 [1426]\n",
      "stipulates [1175]\n",
      "reports [1797]\n",
      "farageforever [88]\n",
      "bbcone [483, 666, 1010, 1103, 1656]\n",
      "reactivates [994]\n",
      "deaths [1376]\n",
      "unio [1470]\n",
      "campaign [433, 653, 1485, 1536]\n",
      "straw [1612]\n",
      " üëèüèø\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "#wdict is the dictionary used to note the occurence of a particular words in several tweets.\n",
    "wdict = defaultdict(lambda: [])\n",
    "\n",
    "for i in xrange(2000):\n",
    "    tweet = str(df.loc[i]['text'])\n",
    "    for each in tweet.split():\n",
    "        words = re.findall(r'\\w+',each)\n",
    "        for word in words:\n",
    "            wdict[word].append(i)\n",
    "            \n",
    "print \"Word in Tweet  ||\", \"Tweet Nos.\"\n",
    "\n",
    "for i,each in enumerate(wdict.keys()):\n",
    "    if i<100:\n",
    "        print each,wdict[each] #Printing only 100 words.\n",
    "\n",
    "#This tweet has no words. It raises a warning when we do TFIDF, because Nj becomes zero.\n",
    "print df.loc[1729]['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in dataset: 3240\n",
      "The 100 most frequent words and their frequencies in the dataset:\n",
      "miliband 658\n",
      "snp 613\n",
      "s 552\n",
      "tories 363\n",
      "t 358\n",
      "labour 318\n",
      "bbcqt 313\n",
      "ukip 254\n",
      "tory 236\n",
      "david 205\n",
      "http 202\n",
      "1 197\n",
      "lab 129\n",
      "i 121\n",
      "it 118\n",
      "amp 118\n",
      "ge2015 112\n",
      "cameron 111\n",
      "scotland 102\n",
      "he 99\n",
      "poll 91\n",
      "co 90\n",
      "leader 88\n",
      "con 86\n",
      "tonight 84\n",
      "m 82\n",
      "milliband 76\n",
      "5 76\n",
      "sturgeon 74\n",
      "8 72\n",
      "d 70\n",
      "ft 66\n",
      "34 66\n",
      "don 65\n",
      "ed_miliband 65\n",
      "grn 60\n",
      "yougov 59\n",
      "nicola 59\n",
      "scottish 59\n",
      "35 59\n",
      "12 58\n",
      "farage 55\n",
      "bbc 53\n",
      "won 47\n",
      "election 46\n",
      "benefit 46\n",
      "ll 46\n",
      "coalition 44\n",
      "eu 42\n",
      "clegg 41\n",
      "here 39\n",
      "backing 39\n",
      "30 39\n",
      "gov 38\n",
      "govt 38\n",
      "ldem 38\n",
      "29 37\n",
      "you 35\n",
      "votesnp 35\n",
      "can 34\n",
      "sun 34\n",
      "england 34\n",
      "jimforscotland 33\n",
      "re 33\n",
      "apr 33\n",
      "nigel 32\n",
      "that 32\n",
      "we 31\n",
      "note 31\n",
      "rule 31\n",
      "boris 30\n",
      "guardian 29\n",
      "deals 29\n",
      "there 29\n",
      "unrelated 28\n",
      "ford 28\n",
      "ed 28\n",
      "doesn 28\n",
      "next 28\n",
      "jonathan 28\n",
      "faces 27\n",
      "scots 27\n",
      "clear 27\n",
      "him 27\n",
      "stage 27\n",
      "cuts 26\n",
      "questions 26\n",
      "let 26\n",
      "westminster 25\n",
      "grilled 24\n",
      "w 24\n",
      "they 23\n",
      "prefers 23\n",
      "uk 23\n",
      "nhs 22\n",
      "uklabour 22\n",
      "to 21\n",
      "power 21\n",
      "page 21\n",
      "lib 20\n"
     ]
    }
   ],
   "source": [
    "print \"Number of unique words in dataset:\", len(wdict.keys())\n",
    "print \"The 100 most frequent words and their frequencies in the dataset:\"\n",
    "\n",
    "sorted_words = sorted(wdict.keys(), key=lambda k: len(wdict[k]),reverse=True)\n",
    "\n",
    "for ind in xrange(100):\n",
    "    print sorted_words[ind],len(wdict[sorted_words[ind]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wdict.keys()) #No. of unique words without stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "engstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934\n"
     ]
    }
   ],
   "source": [
    "#Let's examine the benefits of stemming now. We earlier showed that 3240 unique words are present in tweets.\n",
    "\n",
    "wset = set() \n",
    "\n",
    "for i in xrange(2000):\n",
    "    tweet = str(df.loc[i]['text'])\n",
    "    for each in tweet.split():\n",
    "        words = re.findall(r'\\w+',each)\n",
    "        for word in words:\n",
    "            wset.add(engstemmer.stem(word))\n",
    "\n",
    "print len(wset) #The no. of unique words, after stemming is, 15497. So, stemming helps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in dataset: 2934\n",
      "The 100 most frequent words in the dataset:\n",
      "miliband 658\n",
      "snp 613\n",
      "tori 601\n",
      "s 552\n",
      "t 358\n",
      "labour 319\n",
      "bbcqt 313\n",
      "ukip 255\n",
      "david 205\n",
      "http 202\n",
      "1 197\n",
      "lab 130\n",
      "i 121\n",
      "it 118\n",
      "amp 118\n",
      "ge2015 112\n",
      "cameron 112\n",
      "scotland 103\n",
      "poll 101\n",
      "he 99\n",
      "leader 97\n",
      "co 90\n",
      "con 87\n",
      "tonight 84\n",
      "m 82\n",
      "milliband 77\n",
      "5 76\n",
      "sturgeon 74\n",
      "8 72\n",
      "d 70\n",
      "ft 66\n",
      "34 66\n",
      "don 65\n",
      "ed_miliband 65\n",
      "benefit 61\n",
      "grn 60\n",
      "yougov 59\n",
      "nicola 59\n",
      "scottish 59\n",
      "35 59\n",
      "12 58\n",
      "farag 55\n",
      "bbc 53\n",
      "deal 50\n",
      "coalit 49\n",
      "rule 48\n",
      "won 47\n",
      "elect 46\n",
      "back 46\n",
      "ll 46\n",
      "eu 42\n",
      "clegg 41\n",
      "here 39\n",
      "30 39\n",
      "gov 38\n",
      "govt 38\n",
      "ldem 38\n",
      "grill 37\n",
      "29 37\n",
      "you 35\n",
      "sun 35\n",
      "votesnp 35\n",
      "can 34\n",
      "england 34\n",
      "let 34\n",
      "jimforscotland 33\n",
      "re 33\n",
      "note 33\n",
      "apr 33\n",
      "nigel 32\n",
      "that 32\n",
      "we 31\n",
      "question 31\n",
      "face 31\n",
      "bori 30\n",
      "scot 30\n",
      "guardian 29\n",
      "confirm 29\n",
      "cut 29\n",
      "there 29\n",
      "ford 28\n",
      "unrel 28\n",
      "ed 28\n",
      "clear 28\n",
      "doesn 28\n",
      "next 28\n",
      "jonathan 28\n",
      "parti 28\n",
      "govern 27\n",
      "seat 27\n",
      "him 27\n",
      "stage 27\n",
      "prefer 26\n",
      "power 26\n",
      "trip 25\n",
      "westminst 25\n",
      "w 24\n",
      "they 23\n",
      "uk 23\n",
      "nhs 22\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate unique words and their frequencies without making stemming permanent in the csv file. \n",
    "#We assign a new object to the wdict dictionary we created before-stemming in this notebook.\n",
    "\n",
    "#wdict is the dictionary used to note the occurence of a particular unique word in several tweets.\n",
    "wdict = defaultdict(lambda: [])\n",
    "\n",
    "for i in xrange(2000):\n",
    "    tweet = str(df.loc[i]['text'])\n",
    "    \n",
    "    for each in tweet.split():\n",
    "        words = re.findall(r'\\w+',each)\n",
    "        \n",
    "        for word in words:\n",
    "            wdict[engstemmer.stem(word)].append(i) \n",
    "\n",
    "print \"Number of unique words in dataset:\", len(wdict.keys())\n",
    "print \"The 100 most frequent words in the dataset:\"\n",
    "\n",
    "sorted_words = sorted(wdict.keys(), key=lambda k: len(wdict[k]),reverse=True)\n",
    "\n",
    "for index in xrange(100):\n",
    "    print sorted_words[index],len(wdict[sorted_words[index]]) \n",
    "#Note that the frequencies are better calculated with stemming.\n",
    "#More importantly, whole order is reshuffled, e.g: 'tori' i.e. stem('tories')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "word_matrix = np.zeros((len(wdict.keys()),2000)) #our matrix is no. of unique words * no. of tweets in size.\n",
    "\n",
    "for index,word in enumerate(wdict.keys()):\n",
    "    for tweetno in wdict[word]:\n",
    "        word_matrix[index,tweetno] += 1\n",
    "\n",
    "print word_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We use sorted_words instead of wdict.keys() to reflect frequency of use of that word.\n",
    "#i.e. we save the words in order of their decreasing frequency in the dataset.\n",
    "df2 = pd.DataFrame(0,index=sorted_words,columns=xrange(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for word in sorted_words:\n",
    "    for tweetno in wdict[word]:\n",
    "        df2.ix[word,tweetno] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2.index.name = 'WORDS In Tweets\\Tweet No.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORDS In Tweets\\Tweet No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miliband</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tori</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0     1     2     3     4     5     6     7     \\\n",
       "WORDS In Tweets\\Tweet No.                                                   \n",
       "miliband                      0     0     0     0     0     0     0     0   \n",
       "snp                           0     0     0     0     0     0     0     0   \n",
       "tori                          0     0     0     0     0     0     0     1   \n",
       "s                             0     0     0     0     1     0     0     1   \n",
       "t                             0     0     0     0     1     0     0     0   \n",
       "\n",
       "                           8     9     ...   1990  1991  1992  1993  1994  \\\n",
       "WORDS In Tweets\\Tweet No.              ...                                  \n",
       "miliband                      1     0  ...      0     0     0     0     1   \n",
       "snp                           0     0  ...      1     1     1     0     0   \n",
       "tori                          0     0  ...      0     2     0     0     1   \n",
       "s                             1     1  ...      0     1     0     0     0   \n",
       "t                             0     0  ...      0     0     0     0     0   \n",
       "\n",
       "                           1995  1996  1997  1998  1999  \n",
       "WORDS In Tweets\\Tweet No.                                \n",
       "miliband                      0     0     0     0     1  \n",
       "snp                           0     0     0     0     2  \n",
       "tori                          1     1     0     1     1  \n",
       "s                             1     1     0     0     0  \n",
       "t                             0     0     1     0     0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('wordmatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('wordmatrix.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORDS In Tweets\\Tweet No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miliband</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tori</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0  1  2  3  4  5  6  7  8  9  ...   1990  1991  \\\n",
       "WORDS In Tweets\\Tweet No.                                ...                \n",
       "miliband                   0  0  0  0  0  0  0  0  1  0  ...      0     0   \n",
       "snp                        0  0  0  0  0  0  0  0  0  0  ...      1     1   \n",
       "tori                       0  0  0  0  0  0  0  1  0  0  ...      0     2   \n",
       "s                          0  0  0  0  1  0  0  1  1  1  ...      0     1   \n",
       "t                          0  0  0  0  1  0  0  0  0  0  ...      0     0   \n",
       "\n",
       "                           1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "WORDS In Tweets\\Tweet No.                                                  \n",
       "miliband                      0     0     1     0     0     0     0     1  \n",
       "snp                           1     0     0     0     0     0     0     2  \n",
       "tori                          0     0     1     1     1     0     1     1  \n",
       "s                             0     0     0     1     1     0     0     0  \n",
       "t                             0     0     0     0     0     1     0     0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
